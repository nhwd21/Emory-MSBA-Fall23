# -*- coding: utf-8 -*-
"""HW2_kNN_LR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gg80EizDofw3_MqUwwn9CTAz6uJFyLMU

## Data Processing
"""

# read data from http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data

import pandas as pd
import numpy as np

df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', header=None)

df.columns = ['id', 'diagnosis', 'radius_mean',  'texture_mean',  'perimeter_mean',  'area_mean',  'smoothness_mean',  'compactness_mean',  'concavity_mean',  'concave_points_mean',  'symmetry_mean',  'fractal_dimension_mean',
                                 'radius_se',    'texture_se',    'perimeter_se',    'area_se',    'smoothness_se',    'compactness_se',    'concavity_se',    'concave_points_se',    'symmetry_se',    'fractal_dimension_se',
                                 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave_points_worst', 'symmetry_worst', 'fractal_dimension_worst']

df.head()

#is a classifier problem
df.diagnosis.unique()

# explore the data by reporting summary statistics and a correlation matrix
df.describe()

df.info()

# Calculate skewness for each column
skewness_scores = df.skew(numeric_only=True)

# Print or return the skewness scores
print(skewness_scores)

#check the SE variables which are highly skewed
import pandas as pd
import matplotlib.pyplot as plt

# Assuming df is your DataFrame
columns_to_check = ['radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se', 'fractal_dimension_se']

# Create a figure with subplots
fig, axes = plt.subplots(nrows=1, ncols=len(columns_to_check), figsize=(20, 5))

# Iterate through columns and plot histograms
for i, column in enumerate(columns_to_check):
    axes[i].hist(df[column], bins=20, edgecolor='k')
    axes[i].set_title(column)
    axes[i].set_xlabel('Value')
    axes[i].set_ylabel('Frequency')

plt.tight_layout()
plt.show()

# plot df.corr() as a heatmap with seaborn

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(20,20))
sns.heatmap(df.corr(), annot=True, fmt=".2f",cmap='RdYlGn')
plt.show()

"""## Modeling

KNN
"""

from sklearn.model_selection import train_test_split
from sklearn.discriminant_analysis import StandardScaler
X_knn = df.drop(['id','diagnosis'],axis=1)
y_knn = df.diagnosis

X_train, X_test, y_train, y_test = train_test_split(X_knn,y_knn,test_size=0.3,random_state=1, stratify=y_knn)

# Normalization/Standardization
# Instantiate StandardScaler
sc = StandardScaler()
# Fitting the StandardScaler
sc.fit(X_train)

# Transforming the datasets
X_train_std = sc.transform(X_train)
X_test_std = sc.transform(X_test)

# Perform a predictive modeling analysis on this dataset to predict the type (benign B or malignant M) using a k-NN technique (for k=3)

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train_std,y_train)
y_pred = knn.predict(X_test_std)

# generalization performance of the kNN model.
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score

print('Accuracy score for k=3 is: ',accuracy_score(y_test,y_pred))
print('Confusion matrix for k-NN is: \n',confusion_matrix(y_test,y_pred))
print('Classification report for k-NN is: \n',classification_report(y_test,y_pred))

"""Logistic Regression"""

df['diagnosis'] = df['diagnosis'].replace({'M': 1, 'B': 0})

# Calculate the correlation of each feature (except first two columns) with the target variable
correlation_with_target = df.iloc[:, 2:].corrwith(df['diagnosis']).abs()

# Create the correlation matrix for all columns except the first two
corrmatrix = df.iloc[:, 2:].corr().abs()

# Get pairs of highly correlated features
high_corr_var = np.where(corrmatrix > 0.9)
high_corr_var = [(corrmatrix.columns[x], corrmatrix.columns[y]) for x, y in zip(*high_corr_var) if x != y and x < y]

# Drop one of each pair based on correlation with target
for var1, var2 in high_corr_var:
    if correlation_with_target[var1] > correlation_with_target[var2]:
        df.drop(var2, axis=1, inplace=True, errors='ignore')
    else:
        df.drop(var1, axis=1, inplace=True, errors='ignore')

plt.figure(figsize=(20,20))
sns.heatmap(df.corr(), annot=True, fmt=".2f",cmap='RdYlGn')
plt.show()

X = df.drop(['id','diagnosis'],axis=1)
y = df.diagnosis

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=1, stratify=y)

# Perform a predictive modeling analysis on this dataset to predict the type (benign B or malignant M) using Logistic Regression technique
# X unstandardized
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
from sklearn import metrics

clf = LogisticRegression(multi_class='auto',  # multi_class='auto' indicates that the classifier should handle multi-class classification automatically
                                         C=1,                 # C=1 specifies the regularization strength (smaller values of C correspond to stronger regularization)
                                         max_iter=200)       # maximum number of iterations taken for the solvers to converge

clf.fit(X_train,y_train)
y_pred_lr = clf.predict(X_test)

print('attributes are:', X_train.columns)
print('The weights of the attributes are:', clf.coef_)
print('The weights of the intercepts are:', clf.intercept_)
print('Accuracy score for Logistic Regression is: ',accuracy_score(y_test,y_pred_lr))

# generalization performance of the Logistic Regression model.

print('Accuracy score for Logistic Regression is: ',accuracy_score(y_test,y_pred_lr))
print('Confusion matrix for Logistic Regression is: \n',confusion_matrix(y_test,y_pred_lr))
print('Classification report for Logistic Regression is: \n',classification_report(y_test,y_pred_lr))

"""## Optional but we tried: cross validation below"""

# Perform a predictive modeling analysis on this dataset to predict the type (benign B or malignant M) using Logistic Regression technique
# with cross validation
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
from sklearn import metrics

#for kNN:
sc = StandardScaler()
sc.fit(X_knn)

X_knn_std = sc.transform(X_knn)

# for LR:
X = df.drop(['id','diagnosis'],axis=1)
y = df.diagnosis

#kNN with cross validation
clf_knn = KNeighborsClassifier(n_neighbors=3)

scores=cross_val_score(clf_knn,                # specify the model to use to fit the data
                                              # in this case, the kNN classifier
                       X_knn_std,  # the data to fit. Can be for example a list, or an array
                                              # the features used for training are petal length and petal width
                       y,           # the target variable to try to predict
                       cv=5)                  # specify the number of folds (if the estimator is a classifier and y is either binary or multiclass,
                                              # sStratifiedKFold is used)

print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
# prints the accuracy scores for each fold
print(scores)

# F-1 scores
# print the mean F1 score and its confidence interval
scores_f1=cross_val_score(clf_knn,               # the model to use to fit the data
                          X_knn_std, # the data to fit. Can be for example a list, or an array
                          y,          # the target variable to try to predict
                          cv=5,                # specify the number of folds (if the estimator is a classifier and y is either binary or
                                                # multiclass, StratifiedKFold is used)
                          scoring='f1_macro')   # the macro-average F1 score should be used as the scoring metric

# prints the F1 scores for each fold
print("F1-score: %0.2f (+/- %0.2f)" % (scores_f1.mean(), scores_f1.std() * 2)) # returns an array of scores of the estimator for each run
print(scores_f1)

#LR with cross validation
clf_lr = LogisticRegression(multi_class='auto',  # multi_class='auto' indicates that the classifier should handle multi-class classification automatically
                                         C=1,                 # C=1 specifies the regularization strength (smaller values of C correspond to stronger regularization)
                                         max_iter=200)        #  maximum number of iterations for optimization

scores=cross_val_score(clf_lr,                # specify the model to use to fit the data
                                              # in this case, the logistic regression classifier
                       X,  # the data to fit. Can be for example a list, or an array
                                              # the features used for training are petal length and petal width
                       y,           # the target variable to try to predict
                       cv=5)                  # specify the number of folds (if the estimator is a classifier and y is either binary or multiclass,
                                              # sStratifiedKFold is used)

print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
# prints the accuracy scores for each fold
print(scores)

# F-1 scores
# print the mean F1 score and its confidence interval
scores_f1=cross_val_score(clf_lr,               # the model to use to fit the data
                          X, # the data to fit. Can be for example a list, or an array
                          y,          # the target variable to try to predict
                          cv=5,                # specify the number of folds (if the estimator is a classifier and y is either binary or
                                                # multiclass, StratifiedKFold is used)
                          scoring='f1_macro')   # the macro-average F1 score should be used as the scoring metric

# prints the F1 scores for each fold
print("F1-score: %0.2f (+/- %0.2f)" % (scores_f1.mean(), scores_f1.std() * 2)) # returns an array of scores of the estimator for each run
print(scores_f1)

