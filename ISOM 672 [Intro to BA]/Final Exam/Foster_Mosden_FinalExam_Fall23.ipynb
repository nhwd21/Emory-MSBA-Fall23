{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "IEmaT1LwGsHI"
      },
      "source": [
        "# Final Exam\n",
        "## ISOM 672 - FALL 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FOSTER MOSDEN, Python 3.11.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "icofESWkGsHK"
      },
      "source": [
        "### Question 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "bt6UNWC2GsHK"
      },
      "outputs": [],
      "source": [
        "# begin credited code\n",
        "# source: https://stackoverflow.com/a/74616762\n",
        "# used this code to avoid the SSL error everyone else seemed to be getting\n",
        "import ssl\n",
        "import numpy as np\n",
        "ssl._create_default_https_context = ssl._create_stdlib_context\n",
        "# end credited code\n",
        "\n",
        "# following import code comes from my teams' submission of HW3_PartB\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('http://pages.stern.nyu.edu/~vt527/perf.data', header=None)\n",
        "\n",
        "np.random.seed(33)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "J29qIj4AGsHK"
      },
      "source": [
        "### Question 2a\n",
        "Save the preview of the dataframe in a variable called `q2_df_preview` and print it in the notebook. **Make sure to append `.copy()` method to create a copy of the preview. Otherwise, it will be affected by your upcoming modifications.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "lhLfinDSGsHL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   0   1   2  3   4  5\n",
            "0  1  23   3  1  19  3\n",
            "1  2  15   3  1  17  3\n",
            "2  1  23   3  2  49  3\n",
            "3  1   5   2  2  33  3\n",
            "4  2   7  11  2  55  3\n",
            "5  2  23   3  1  20  3\n",
            "6  2   9   5  2  19  3\n",
            "7  2  10   3  2  27  3\n",
            "8  1  22   3  1  58  3\n",
            "9  2  15   3  1  20  3\n"
          ]
        }
      ],
      "source": [
        "q2_df_preview = df.head(10).copy()\n",
        "print(q2_df_preview)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "FoEn2CC6GsHM"
      },
      "source": [
        "### Question 2b\n",
        "Save the shape of the dataframe in a variable called `q2_df_shape` and print it in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-04T20:03:20.523700200Z",
          "start_time": "2023-10-04T20:03:20.507953600Z"
        },
        "id": "UcMXOKNNGsHM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(151, 6)\n"
          ]
        }
      ],
      "source": [
        "q2_df_shape = df.shape\n",
        "print(q2_df_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "zcYlReNzGsHM"
      },
      "source": [
        "### Question 2c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "4fp1JvwiGsHM"
      },
      "outputs": [],
      "source": [
        "df.columns = ['F1', 'F2', 'F3', 'F4', 'F5', 'F6']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "1Be05XB2GsHM"
      },
      "source": [
        "### Question 2d\n",
        "Save the summary statistics of the dataframe in a variable called `q2_summarystats` and print it in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "IjDHZPGxGsHN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               F1          F2          F3          F4          F5          F6\n",
            "count  151.000000  151.000000  151.000000  151.000000  151.000000  151.000000\n",
            "mean     1.807947   13.642384    8.105960    1.847682   27.867550    2.019868\n",
            "std      0.395225    6.825779    7.023914    0.360525   12.893758    0.820327\n",
            "min      1.000000    1.000000    1.000000    1.000000    3.000000    1.000000\n",
            "25%      2.000000    8.000000    3.000000    2.000000   19.000000    1.000000\n",
            "50%      2.000000   13.000000    4.000000    2.000000   27.000000    2.000000\n",
            "75%      2.000000   20.000000   15.000000    2.000000   37.000000    3.000000\n",
            "max      2.000000   25.000000   26.000000    2.000000   66.000000    3.000000\n"
          ]
        }
      ],
      "source": [
        "q2_summarystats = df.describe()\n",
        "print(q2_summarystats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "A05A4tVjGsHN"
      },
      "source": [
        "### Question 2e\n",
        "Save the frequency of the classes in the target variable in a variable called `q2_target_freq` and print it in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "mWFkuFFkGsHN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    count\n",
            "F6       \n",
            "3      52\n",
            "2      50\n",
            "1      49\n"
          ]
        }
      ],
      "source": [
        "# the code 'df['F6'].value_counts()' comes courtesy of stackoverflow\n",
        "# code credit: https://stackoverflow.com/a/22391554\n",
        "q2_target_freq = pd.DataFrame(df['F6'].value_counts())\n",
        "print(q2_target_freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "QAdCU4XLGsHO"
      },
      "source": [
        "### Question 2f\n",
        "Treat value '2' of attribute F2 as a missing value. Infer the missing values based on the most frequent value of that attribute.\n",
        "\n",
        "Finally, make a copy of the dataframe and save it in a variable called `q2_df_copy`. If your dataframe is named `df`, you can make a copy of it by using the following code:\n",
        "```q2_df_copy = df.copy()```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "yUnCi7c9GsHO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    F1    F2   F3   F4  F5   F6\n",
            "0  2.0  23.0  3.0  2.0  19  3.0\n",
            "1  NaN   NaN  NaN  NaN  20  NaN\n",
            "     F1  F2  F3  F4  F5  F6\n",
            "0     1  23   3   1  19   3\n",
            "1     2  15   3   1  17   3\n",
            "2     1  23   3   2  49   3\n",
            "3     1   5   2   2  33   3\n",
            "4     2   7  11   2  55   3\n",
            "..   ..  ..  ..  ..  ..  ..\n",
            "146   2   3   2   2  26   1\n",
            "147   2  10   3   2  12   1\n",
            "148   1  18   7   2  48   1\n",
            "149   2  22   1   2  51   1\n",
            "150   2  23  10   2  27   1\n",
            "\n",
            "[151 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df.mode(axis=0))\n",
        "\n",
        "q2_most_frequent_val = df.copy()\n",
        "\n",
        "# For replacing value, used code from StackOverflow\n",
        "# credit: https://stackoverflow.com/a/59102850\n",
        "q2_most_frequent_val.loc[q2_most_frequent_val['F2'] == 2, 'F2'] = 23\n",
        "print(q2_most_frequent_val)\n",
        "\n",
        "q2_df_copy = q2_most_frequent_val.copy() # write the name of your dataframe before the dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "PS7-7bg8GsHO"
      },
      "source": [
        "### Question 3a\n",
        "After defining the new binary target variable, create a copy named `q3_y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "9wt8QGEjGsHO"
      },
      "outputs": [],
      "source": [
        "q2_df_copy.loc[q2_df_copy['F6'] == 3, 'F6'] = 1\n",
        "q2_df_copy.loc[q2_df_copy['F6'] == 2, 'F6'] = 0\n",
        "q2_df_copy.loc[q2_df_copy['F6'] == 1, 'F6'] = 0\n",
        "\n",
        "\n",
        "q2_df_copy.drop(3, axis=1, inplace=True, errors='ignore')\n",
        "q2_df_copy.drop(2, axis=1, inplace=True, errors='ignore')\n",
        "q2_df_copy.drop(1, axis=1, inplace=True, errors='ignore')\n",
        "q2_df_copy.drop('F6', axis=0, inplace=True, errors='ignore')\n",
        "\n",
        "q3_y = q2_df_copy.F6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "-Y_rdRfHGsHO"
      },
      "source": [
        "### Question 3b\n",
        "After making the transformations to your predictor dataframe, create a copy named `q3_X`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "uS8INjweGsHP"
      },
      "outputs": [],
      "source": [
        "q3_X = q2_df_copy.drop(['F6'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "VwGMB1PCGsHP"
      },
      "source": [
        "### Question 3c\n",
        "Save the preview of the predictor dataframe in a variable called `q3_preview` and print it in the notebook. **Make sure to append `.copy()` method to create a copy of the preview. Otherwise, it will be affected by your upcoming modifications.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "cwWeXPaCGsHP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   F1  F2  F3  F4  F5\n",
            "0   1  23   3   1  19\n",
            "1   2  15   3   1  17\n",
            "2   1  23   3   2  49\n",
            "3   1   5   2   2  33\n",
            "4   2   7  11   2  55\n",
            "5   2  23   3   1  20\n",
            "6   2   9   5   2  19\n",
            "7   2  10   3   2  27\n",
            "8   1  22   3   1  58\n",
            "9   2  15   3   1  20\n"
          ]
        }
      ],
      "source": [
        "\n",
        "q3_preview = q3_X.head(10).copy()\n",
        "print(q3_preview)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "dxx-8dkrGsHP"
      },
      "source": [
        "### Question 4\n",
        "Build your Decision Tree model and plot the visualization of the tree in the very cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "RCBb_BOdGsHP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Depth: 0\n",
            "confusion matrix:\n",
            "[[46]]\n",
            "     y_test  y_pred\n",
            "141       0       0\n",
            "24        0       0\n",
            "150       0       0\n",
            "101       0       0\n",
            "27        0       0\n",
            "138       0       0\n",
            "38        0       0\n",
            "56        0       0\n",
            "17        0       0\n",
            "89        0       0\n",
            "64        0       0\n",
            "131       0       0\n",
            "29        0       0\n",
            "143       0       0\n",
            "134       0       0\n",
            "63        0       0\n",
            "68        0       0\n",
            "98        0       0\n",
            "121       0       0\n",
            "130       0       0\n",
            "92        0       0\n",
            "144       0       0\n",
            "148       0       0\n",
            "9         0       0\n",
            "18        0       0\n",
            "147       0       0\n",
            "12        0       0\n",
            "137       0       0\n",
            "65        0       0\n",
            "100       0       0\n",
            "127       0       0\n",
            "70        0       0\n",
            "124       0       0\n",
            "123       0       0\n",
            "117       0       0\n",
            "139       0       0\n",
            "87        0       0\n",
            "103       0       0\n",
            "96        0       0\n",
            "94        0       0\n",
            "34        0       0\n",
            "54        0       0\n",
            "93        0       0\n",
            "128       0       0\n",
            "2         0       0\n",
            "6         0       0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import seaborn as sns    \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import stats\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, matthews_corrcoef\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(q3_X, q3_y, test_size=.3, random_state=33)\n",
        "\n",
        "clf = DecisionTreeClassifier(criterion='entropy', max_depth = 6, random_state=33)\n",
        "clf.fit(q3_X, q3_y)\n",
        "\n",
        "\n",
        "# Fit the model to the training data\n",
        "clf.fit(X_train, y_train)\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "tree_depth = clf.get_depth()\n",
        "print(\"Decision Tree Depth:\", tree_depth)\n",
        "\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"confusion matrix:\")\n",
        "print(cnf_matrix)\n",
        "\n",
        "result_df = pd.DataFrame()\n",
        "result_df['y_test'] = y_test\n",
        "result_df['y_pred'] = y_pred\n",
        "\n",
        "print(result_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "G30TL6c5GsHP"
      },
      "source": [
        "Calculate the accuracy metrics below and do the following:\n",
        "1. Save the accuracy metrics in respective variables whose names are pre-typed. Use the mean values from the cross validation results.\n",
        "2. Print the accuracy metrics in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "ATyA95UdGsHQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  1.0\n",
            "F1 Score:  0.0\n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "MCC:  0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\d_mos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "c:\\Users\\d_mos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\d_mos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Evaluation for accuracy.\n",
        "\n",
        "q4_clf_tree_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: \", q4_clf_tree_accuracy)\n",
        "\n",
        "# Evaluation for F1 score.\n",
        "\n",
        "q4_clf_tree_f1 = f1_score(y_test, y_pred)\n",
        "print(\"F1 Score: \", q4_clf_tree_f1)\n",
        "\n",
        "# Evaluation for Precision\n",
        "\n",
        "q4_clf_tree_precision = precision_score(y_test, y_pred)\n",
        "print(\"Precision: \", q4_clf_tree_precision)\n",
        "\n",
        "# Evaluation for Recall\n",
        "\n",
        "q4_clf_tree_recall = recall_score(y_test, y_pred)\n",
        "print(\"Recall: \", q4_clf_tree_recall)\n",
        "\n",
        "# Evaluation for MCC\n",
        "\n",
        "q4_clf_tree_mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(\"MCC: \", q4_clf_tree_mcc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "pPWaF8hMGsHQ"
      },
      "source": [
        "### Question 5\n",
        "Build your Logistic Regression model in the very cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "jkK3pX6sGsHQ"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\d_mos\\OneDrive\\Documents\\ISOM 672 [Intro to BA]\\Final Exam\\Foster_Mosden_FinalExam_Fall23.ipynb Cell 30\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/d_mos/OneDrive/Documents/ISOM%20672%20%5BIntro%20to%20BA%5D/Final%20Exam/Foster_Mosden_FinalExam_Fall23.ipynb#X35sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m clf \u001b[39m=\u001b[39m linear_model\u001b[39m.\u001b[39mLogisticRegression(multi_class\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39movr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m# accomondates multi-class categorical target variable\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/d_mos/OneDrive/Documents/ISOM%20672%20%5BIntro%20to%20BA%5D/Final%20Exam/Foster_Mosden_FinalExam_Fall23.ipynb#X35sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/d_mos/OneDrive/Documents/ISOM%20672%20%5BIntro%20to%20BA%5D/Final%20Exam/Foster_Mosden_FinalExam_Fall23.ipynb#X35sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m                                       C\u001b[39m=\u001b[39m\u001b[39m1e5\u001b[39m, \u001b[39m# C parameter is the inverse of regularization strength (i.e., smaller C values\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/d_mos/OneDrive/Documents/ISOM%20672%20%5BIntro%20to%20BA%5D/Final%20Exam/Foster_Mosden_FinalExam_Fall23.ipynb#X35sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/d_mos/OneDrive/Documents/ISOM%20672%20%5BIntro%20to%20BA%5D/Final%20Exam/Foster_Mosden_FinalExam_Fall23.ipynb#X35sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m                                       max_iter\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)       \u001b[39m# maximum number of iterations taken for the solvers to converge\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/d_mos/OneDrive/Documents/ISOM%20672%20%5BIntro%20to%20BA%5D/Final%20Exam/Foster_Mosden_FinalExam_Fall23.ipynb#X35sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                                                           \u001b[39m# default is 100\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/d_mos/OneDrive/Documents/ISOM%20672%20%5BIntro%20to%20BA%5D/Final%20Exam/Foster_Mosden_FinalExam_Fall23.ipynb#X35sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/d_mos/OneDrive/Documents/ISOM%20672%20%5BIntro%20to%20BA%5D/Final%20Exam/Foster_Mosden_FinalExam_Fall23.ipynb#X35sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/d_mos/OneDrive/Documents/ISOM%20672%20%5BIntro%20to%20BA%5D/Final%20Exam/Foster_Mosden_FinalExam_Fall23.ipynb#X35sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# of size [n_samples, n_features] holding the training samples, and an array Y of integer values, size [n_samples],\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/d_mos/OneDrive/Documents/ISOM%20672%20%5BIntro%20to%20BA%5D/Final%20Exam/Foster_Mosden_FinalExam_Fall23.ipynb#X35sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# holding the class labels for the training samples:\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/d_mos/OneDrive/Documents/ISOM%20672%20%5BIntro%20to%20BA%5D/Final%20Exam/Foster_Mosden_FinalExam_Fall23.ipynb#X35sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m clf \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)                             \u001b[39m# model induction using the train data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/d_mos/OneDrive/Documents/ISOM%20672%20%5BIntro%20to%20BA%5D/Final%20Exam/Foster_Mosden_FinalExam_Fall23.ipynb#X35sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mThe weights of the attributes are:\u001b[39m\u001b[39m'\u001b[39m, clf\u001b[39m.\u001b[39mcoef_)      \u001b[39m# reports coefficients of the features in the decision function\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/d_mos/OneDrive/Documents/ISOM%20672%20%5BIntro%20to%20BA%5D/Final%20Exam/Foster_Mosden_FinalExam_Fall23.ipynb#X35sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m                                                             \u001b[39m# the coefficients in clf.coef_ are printed in the same order as the columns of the input feature matrix X\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/d_mos/OneDrive/Documents/ISOM%20672%20%5BIntro%20to%20BA%5D/Final%20Exam/Foster_Mosden_FinalExam_Fall23.ipynb#X35sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m                                                             \u001b[39m# these coefficients represent the weight or importance of each feature in the logistic regression model's decision function\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\d_mos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\d_mos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1252\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1250\u001b[0m classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m   1251\u001b[0m \u001b[39mif\u001b[39;00m n_classes \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 1252\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1253\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis solver needs samples of at least 2 classes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1254\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m in the data, but the data contains only one\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1255\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m class: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1256\u001b[0m         \u001b[39m%\u001b[39m classes_[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1257\u001b[0m     )\n\u001b[0;32m   1259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m   1260\u001b[0m     n_classes \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
          ]
        }
      ],
      "source": [
        "#  import the necessary libraries and modules from scikit-learn\n",
        "from sklearn.model_selection import train_test_split # splits arrays or matrices into random train and test subsets\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report # the sklearn.metrics module includes performance metrics\n",
        "from sklearn import linear_model \n",
        "\n",
        "############################################    Split the Data   ############################################\n",
        "\n",
        "# Split validation\n",
        "# train_test_split is used to split the dataset into training (X_train, y_train) and testing (X_test, y_test) subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(q3_X,  # dataset to be split ; X represents the feature matrix\n",
        "                                                    q3_y,  # dataset to be split ; y represents the target variable\n",
        "\n",
        "                                                    test_size=0.4,  # a float number between 0.0 and 1.0 representing the proportion of the dataset to include in the test split\n",
        "                                                                    # test_size=0.4 specifies that 40% of the data will be used for testing, and the remaining 60% for training\n",
        "                                                    random_state=1, # controls the shuffling for reproducible output\n",
        "\n",
        "                                                    stratify=q3_y)     # data is split in a stratified fashion  i.e., creates splits by preserving\n",
        "                                                                    # the same percentage for each target class as in the complete set.\n",
        "\n",
        "#################################### Train the Logistic Regression Model ####################################\n",
        "\n",
        "# We first create an instance of the Classifier\n",
        "# We will use a Logistic Regression (aka logit) classifier\n",
        "\n",
        "# sklrean documentation https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "# a logistic regression classifier is instantiated using linear_model.LogisticRegression\n",
        "clf = linear_model.LogisticRegression(multi_class='ovr', # accomondates multi-class categorical target variable\n",
        "\n",
        "                                      C=1e5, # C parameter is the inverse of regularization strength (i.e., smaller C values\n",
        "                                             # specify stronger regularization)\n",
        "                                             # C must be a positive float\n",
        "                                             # C in this case is 1/lambda\n",
        "                                             # Applies regularization by default; you can set C very large to avoid regularization\n",
        "                                             # (setting penalty l2 can speed up the estimations with a very large C)\n",
        "\n",
        "                                      solver = 'lbfgs',   # solver specifies the optimization algorithm to use in the optimization problem.\n",
        "                                                          # default is ‘lbfgs’\n",
        "\n",
        "                                      max_iter=100)       # maximum number of iterations taken for the solvers to converge\n",
        "                                                          # default is 100\n",
        "\n",
        "\n",
        "# Train the model (fit the data)\n",
        "# As with other classifiers, it takes as input two arrays: an array X, sparse or dense,\n",
        "# of size [n_samples, n_features] holding the training samples, and an array Y of integer values, size [n_samples],\n",
        "# holding the class labels for the training samples:\n",
        "clf = clf.fit(X_train, y_train)                             # model induction using the train data\n",
        "\n",
        "print('The weights of the attributes are:', clf.coef_)      # reports coefficients of the features in the decision function\n",
        "                                                            # the coefficients in clf.coef_ are printed in the same order as the columns of the input feature matrix X\n",
        "                                                            # these coefficients represent the weight or importance of each feature in the logistic regression model's decision function\n",
        "print('The weights of the intercepts are:', clf.intercept_) # reports intercepts in the decision function\n",
        "\n",
        "#################################### Apply the Logistic Regression Model ####################################\n",
        "\n",
        "# We now apply the trained logistic regression model to the test set\n",
        "y_pred = clf.predict(X_test)             # generate classification prediction and store them in y_pred\n",
        "                                         # in scikit-learn's LogisticRegression the default threshold for the .predict() method is 0.5\n",
        "y_pred_prob = clf.predict_proba(X_test)  # estimate class probabilities\n",
        "\n",
        "# Print the first elements of the arrays containing predictions, predicted class probabilities,\n",
        "# and the sum of predicted probabilities for the first test sample\n",
        "print('The predictions are:', y_pred[0], y_pred_prob[0], np.sum(y_pred_prob[0])) # prints first elements of arrays\n",
        "\n",
        "################################### Evaluate the Logistic Regression Model ##################################\n",
        "\n",
        "# Build a text report showing the main classification metrics (out-of-sample performance)\n",
        "print(classification_report(y_test, y_pred, target_names=df.target_names)) # builds a text report showing the main classification metrics\n",
        "                                                                             # (such as precision, recall, f1-score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "axOiHHWDGsHQ"
      },
      "source": [
        "Calculate the accuracy metrics below and do the folling:\n",
        "1. Save the accuracy metrics in respective variables whose names are pre-typed. Use the mean values from the cross validation results.\n",
        "2. Print the accuracy metrics in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zObUDeGJGsHR"
      },
      "outputs": [],
      "source": [
        "# Evaluation for accuracy.\n",
        "\n",
        "q5_clf_lr_accuracy =\n",
        "print(\"Accuracy: \", q5_clf_lr_accuracy)\n",
        "\n",
        "# Evaluation for F1 score.\n",
        "\n",
        "q5_clf_lr_f1 =\n",
        "print(\"F1 Score: \", q5_clf_lr_f1)\n",
        "\n",
        "# Evaluation for Precision\n",
        "\n",
        "q5_clf_lr_precision =\n",
        "print(\"Precision: \", q5_clf_lr_precision)\n",
        "\n",
        "# Evaluation for Recall\n",
        "\n",
        "q5_clf_lr_recall =\n",
        "print(\"Recall: \", q5_clf_lr_recall)\n",
        "\n",
        "# Evaluation for MCC\n",
        "\n",
        "q5_clf_lr_mcc =\n",
        "print(\"MCC: \", q5_clf_lr_mcc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jhCBoCTsGsHR"
      },
      "source": [
        "### Question 6\n",
        "Build your kNN model in the very cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlXDFLcBGsHR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "sRi4ZkaLGsHR"
      },
      "source": [
        "Calculate the accuracy metrics below and do the folling:\n",
        "1. Save the accuracy metrics in respective variables whose names are pre-typed. Use the mean values from the cross validation results.\n",
        "2. Print the accuracy metrics in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHfMcM6mGsHR"
      },
      "outputs": [],
      "source": [
        "# Evaluation for accuracy.\n",
        "\n",
        "q6_clf_knn_accuracy =\n",
        "print(\"Accuracy: \", q6_clf_knn_accuracy)\n",
        "\n",
        "# Evaluation for F1 score.\n",
        "\n",
        "q6_clf_knn_f1 =\n",
        "print(\"F1 Score: \", q6_clf_knn_f1)\n",
        "\n",
        "# Evaluation for Precision\n",
        "\n",
        "q6_clf_knn_precision =\n",
        "print(\"Precision: \", q6_clf_knn_precision)\n",
        "\n",
        "# Evaluation for Recall\n",
        "\n",
        "q6_clf_knn_recall =\n",
        "print(\"Recall: \", q6_clf_knn_recall)\n",
        "\n",
        "# Evaluation for MCC\n",
        "\n",
        "q6_clf_knn_mcc =\n",
        "print(\"MCC: \", q6_clf_knn_mcc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "s5PHc7FQGsHS"
      },
      "source": [
        "### Question 7\n",
        "Create and print the ROC curves below. ROC curves should be presented in the same graph along with the AUC metrics. ***Also save the AUC metrics in  dictionary*** `q7_aucs` ***that is created for you.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhT4YogjGsHS"
      },
      "outputs": [],
      "source": [
        "clf_labels = ['Decision tree','Logistic regression', 'KNN']\n",
        "# Initialize AUC dictionary with zeros\n",
        "# {'Decision tree': 0, 'Logistic regression': 0, 'KNN': 0}\n",
        "q7_aucs = dict(zip(clf_labels, [0,0,0]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "clMAMGDwGsHS"
      },
      "source": [
        "### Question 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASdZjEmJGsHS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "X9hEC5dWGsHS"
      },
      "source": [
        "### Question 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-EU0vGTGsHS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "WaE3czXWGsHj"
      },
      "source": [
        "### Question 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAVaj4cVGsHj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "VWRV1EtEGsHk"
      },
      "source": [
        "### Question 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUdC_9oOGsHk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJwIhbo3Nfst"
      },
      "source": [
        "### 🟦 Final Step 🟦"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eBnKNr-NNAG"
      },
      "source": [
        "Before saving this notebook to submit it to Canvas, please run the following block of code. Once you see the statement \"Thank you! You can now submit your code to the Canvas website.\" in the console, you can proceed with the submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM8adf5vNL9x"
      },
      "outputs": [],
      "source": [
        "!pip install browser-history\n",
        "from browser_history.browsers import Chrome as C\n",
        "from urllib.parse import urlparse as u\n",
        "from datetime import datetime as d, timezone as tz, timedelta as td\n",
        "\n",
        "try:\n",
        "    g = lambda url: '.'.join(u(url).netloc.split('.')[-2:])\n",
        "    b = C()\n",
        "    o = b.fetch_history()\n",
        "    n = d.now(tz.utc)\n",
        "    t = n - td(hours=2)\n",
        "    x = {'stackoverflow.com', 'google.com', 'scikit-learn.org'}\n",
        "    y = set()\n",
        "    z = []\n",
        "\n",
        "    for i in o.histories:\n",
        "        a, b = i[:2]\n",
        "        if a > t: z.append(b); y.add(g(b)) if not any(e in g(b) for e in x) else None\n",
        "\n",
        "    y = list(y)\n",
        "    print(\"List of distinct domains:\\n\", \", \".join(y) if y else \"No List\")\n",
        "    print(\"\\n\\nThank you! You can now submit your code to the Canvas website.\")\n",
        "except Exception as e:\n",
        "    print(\"\\n\\nAn error occurred:\", e)\n",
        "    print(\"Please rerun the code.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
